{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6aa721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EthioMart/notebooks/data_preprocessing_eda.ipynb\n",
    "\n",
    "# --- Section 1: Setup and Configuration ---\n",
    "\n",
    "# 1.1 Import necessary libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project root to the system path to allow importing from config\n",
    "project_root = Path.cwd().parent # This assumes you run the notebook from EthioMart/notebooks/\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import configuration variables\n",
    "try:\n",
    "    from config.config import DATA_DIR\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import configuration. \"\n",
    "          \"Please ensure EthioMart/config/config.py exists and is correctly configured.\")\n",
    "    # Fallback paths for local testing if config import fails\n",
    "    DATA_DIR = Path(\"../data/raw\") # Fallback to raw data dir, then adjust for processed\n",
    "    \n",
    "\n",
    "# Define the path to your cleaned data CSV file\n",
    "# This should point to EthioMart/data/processed/clean_telegram_data.csv\n",
    "CLEANED_CSV_PATH = DATA_DIR.parent / \"processed\" / \"clean_telegram_data.csv\"\n",
    "\n",
    "\n",
    "# --- Section 2: Load and Inspect Cleaned Data ---\n",
    "\n",
    "print(f\"Loading cleaned data from: {CLEANED_CSV_PATH}\")\n",
    "\n",
    "# Check if the file exists before attempting to load\n",
    "if not CLEANED_CSV_PATH.exists():\n",
    "    print(f\"Error: Cleaned data CSV not found at {CLEANED_CSV_PATH}. \"\n",
    "          \"Please ensure preprocessor.py has been run successfully.\")\n",
    "    df_clean = pd.DataFrame(columns=[ # Define expected columns to prevent errors in later cells\n",
    "        'channel_title', 'message_id', 'date', 'text',\n",
    "        'views', 'reactions_count', 'image_path', 'preprocessed_text'\n",
    "    ]) \n",
    "else:\n",
    "    try:\n",
    "        df_clean = pd.read_csv(CLEANED_CSV_PATH, encoding='utf-8')\n",
    "        print(f\"Successfully loaded {len(df_clean)} cleaned messages.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Warning: Cleaned data CSV at {CLEANED_CSV_PATH} is empty. No data to analyze.\")\n",
    "        df_clean = pd.DataFrame(columns=[\n",
    "            'channel_title', 'message_id', 'date', 'text',\n",
    "            'views', 'reactions_count', 'image_path', 'preprocessed_text'\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading cleaned CSV: {e}\")\n",
    "        df_clean = pd.DataFrame(columns=[\n",
    "            'channel_title', 'message_id', 'date', 'text',\n",
    "            'views', 'reactions_count', 'image_path', 'preprocessed_text'\n",
    "        ])\n",
    "\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(\"\\n--- Cleaned Data DataFrame Info ---\")\n",
    "df_clean.info()\n",
    "\n",
    "# Display the first few rows of the DataFrame, focusing on original vs preprocessed text\n",
    "print(\"\\n--- First 5 Rows of Cleaned Data (Original vs. Preprocessed) ---\")\n",
    "# Ensure 'text' and 'preprocessed_text' columns exist before trying to display them\n",
    "if not df_clean.empty and 'text' in df_clean.columns and 'preprocessed_text' in df_clean.columns:\n",
    "    print(df_clean[['text', 'preprocessed_text']].head())\n",
    "else:\n",
    "    print(\"DataFrame is empty or missing 'text'/'preprocessed_text' columns. Cannot display head.\")\n",
    "\n",
    "\n",
    "# --- Section 3: Exploratory Data Analysis (EDA) on Cleaned Data ---\n",
    "\n",
    "if not df_clean.empty and 'preprocessed_text' in df_clean.columns:\n",
    "    print(\"\\n--- Exploratory Data Analysis on Cleaned Data ---\")\n",
    "\n",
    "    # 3.1 Check for empty preprocessed messages\n",
    "    # Messages that were originally empty will remain empty after preprocessing (which is expected)\n",
    "    # We are interested in messages that had original text but became empty after cleaning\n",
    "    df_clean['preprocessed_text_length'] = df_clean['preprocessed_text'].astype(str).apply(len)\n",
    "    \n",
    "    # Identify messages where original text existed but preprocessed text is empty\n",
    "    messages_turned_empty = df_clean[\n",
    "        (df_clean['text'].notnull()) & \n",
    "        (df_clean['text'] != '') & \n",
    "        (df_clean['preprocessed_text_length'] == 0)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nNumber of messages with original text that became empty after cleaning: {len(messages_turned_empty)}\")\n",
    "    if not messages_turned_empty.empty:\n",
    "        print(\"Sample original texts that became empty:\")\n",
    "        print(messages_turned_empty['text'].head().tolist())\n",
    "\n",
    "\n",
    "    # 3.2 Distribution of preprocessed message length (character count)\n",
    "    print(\"\\nPreprocessed Message Text Length Statistics:\")\n",
    "    print(df_clean['preprocessed_text_length'].describe())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df_clean['preprocessed_text_length'], bins=50, kde=True, color='purple')\n",
    "    plt.title('Distribution of Preprocessed Message Text Lengths')\n",
    "    plt.xlabel('Preprocessed Text Length (characters)')\n",
    "    plt.ylabel('Number of Messages')\n",
    "    plt.show()\n",
    "\n",
    "    # 3.3 Compare original vs. preprocessed text lengths\n",
    "    if 'text' in df_clean.columns and 'preprocessed_text' in df_clean.columns:\n",
    "        df_clean['original_text_length'] = df_clean['text'].astype(str).apply(len)\n",
    "        print(\"\\nText Length Comparison (Original vs. Preprocessed):\")\n",
    "        print(df_clean[['original_text_length', 'preprocessed_text_length']].describe())\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(df_clean['original_text_length'], color='blue', label='Original Length', kde=True, alpha=0.5)\n",
    "        sns.histplot(df_clean['preprocessed_text_length'], color='red', label='Preprocessed Length', kde=True, alpha=0.5)\n",
    "        plt.title('Distribution of Original vs. Preprocessed Text Lengths')\n",
    "        plt.xlabel('Text Length (characters)')\n",
    "        plt.ylabel('Number of Messages')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # 3.4 Top N most frequent words in preprocessed text (basic tokenization for visualization)\n",
    "    from collections import Counter\n",
    "    import itertools\n",
    "\n",
    "    all_words = list(itertools.chain.from_iterable(\n",
    "        df_clean['preprocessed_text'].astype(str).apply(lambda x: x.split()).tolist()\n",
    "    ))\n",
    "    word_counts = Counter(all_words)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Frequent Words in Preprocessed Text:\")\n",
    "    top_words = word_counts.most_common(20)\n",
    "    for word, count in top_words:\n",
    "        print(f\"- {word}: {count}\")\n",
    "\n",
    "    # Visualize top words\n",
    "    if top_words:\n",
    "        words, counts = zip(*top_words)\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.barplot(x=list(counts), y=list(words), palette='cubehelix')\n",
    "        plt.title('Top 20 Most Frequent Words in Preprocessed Text')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Word')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo cleaned data available for EDA. Please ensure preprocessor.py ran successfully.\")\n",
    "\n",
    "\n",
    "# --- Section 4: Visual Inspection of Preprocessing Examples ---\n",
    "\n",
    "print(\"\\n--- Visual Inspection of Preprocessing Examples ---\")\n",
    "# Get some actual samples from the cleaned dataframe to show original vs. processed\n",
    "if not df_clean.empty:\n",
    "    sample_df = df_clean[['text', 'preprocessed_text']].sample(min(5, len(df_clean)), random_state=42)\n",
    "    for index, row in sample_df.iterrows():\n",
    "        print(f\"\\n--- Sample Message ID: {df_clean.loc[index, 'message_id']} ---\")\n",
    "        print(\"Original:\")\n",
    "        print(row['text'])\n",
    "        print(\"\\nCleaned:\")\n",
    "        print(row['preprocessed_text'])\n",
    "else:\n",
    "    print(\"No data loaded to display visual inspection examples.\")\n",
    "\n",
    "\n",
    "# --- Section 5: Next Steps Summary ---\n",
    "\n",
    "print(\"\\n--- Summary of Preprocessing EDA and Next Steps ---\")\n",
    "print(\"This EDA helped us to:\")\n",
    "print(\"- Verify the loading of the 'clean_telegram_data.csv'.\")\n",
    "print(\"- Analyze the distribution of preprocessed text lengths and observe the impact of cleaning.\")\n",
    "print(\"- Identify common words and patterns in the cleaned data.\")\n",
    "print(\"\\nNext, we will proceed with the crucial step of:\")\n",
    "print(\"1. **Data Labeling (`src/labeling.py`)**: Converting your existing 'labeled_telegram_product_price_location.txt' into the CoNLL format, and preparing it for NER model training.\")\n",
    "print(\"2. **Splitting Data**: Dividing the labeled data into training, validation, and test sets.\")\n",
    "print(\"This will complete the data preparation for the NER task.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
